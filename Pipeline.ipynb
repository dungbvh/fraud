{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxcZkpfUWM4m"
      },
      "source": [
        "!pip install missingno xgboost imbalanced-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcyhTcmbvrA7"
      },
      "source": [
        "#@title lib install\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import missingno as msno\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import make_column_selector, make_column_transformer\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBfLntSELrhQ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "df = pd.read_csv(r\"/content/drive/MyDrive/BIDV/CARD_FRAUD/data/all_data_with_header.csv\")\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwUrGVmqDY6D"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5esrfMb9Dd08"
      },
      "source": [
        "target = df['MERCH_FR']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lEVAZMfSGYw"
      },
      "source": [
        "print('kiểu dữ liệu trong tập')\n",
        "print(df.dtypes.unique())\n",
        "print(df.dtypes.nunique())\n",
        "print (df.isnull().values.any())\n",
        "print (df.isna().sum())\n",
        "\n",
        "cols_missing_val = df.columns[df.isnull().any()].tolist()\n",
        "print(cols_missing_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK2f6hcOWkhm"
      },
      "source": [
        "msno.bar(df[cols_missing_val_train],figsize=(20,8),color=\"#19455e\",fontsize=18,labels=True)\n",
        "#msno.matrix(df_train[cols_missing_val_train],width_ratios=(10,1),figsize=(20,8),color=(0.2,0.2,0.2),fontsize=18,sparkline=True,labels=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eED3E-HdfWo"
      },
      "source": [
        "#------- check memory usage---------\n",
        "mem = df.memory_usage(index=True).sum()\n",
        "print(\"Memory consumed by dataset  :   {} MB\" .format(mem/ 1024**2))\n",
        "def change_datatype_int(df):\n",
        "    int_cols = list(df.select_dtypes(include=['int']).columns)\n",
        "    for col in float_cols:\n",
        "        if ((np.max(df[col]) <= 127) and(np.min(df[col] >= -128))):\n",
        "            df[col] = df[col].astype(np.int8)\n",
        "        elif ((np.max(df[col]) <= 32767) and(np.min(df[col] >= -32768))):\n",
        "            df[col] = df[col].astype(np.int16)\n",
        "        elif ((np.max(df[col]) <= 2147483647) and(np.min(df[col] >= -2147483648))):\n",
        "            df[col] = df[col].astype(np.int32)\n",
        "        else:\n",
        "            df[col] = df[col].astype(np.int64)\n",
        "\n",
        "def change_datatype_float(df):\n",
        "    float_cols = list(df.select_dtypes(include=['float']).columns)\n",
        "    for col in float_cols:\n",
        "        df[col] = df[col].astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZJp7i3giGW_"
      },
      "source": [
        "change_datatype_int(df)\n",
        "change_datatype_float(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1l7sL4WjJ1W"
      },
      "source": [
        "# Class proportions are the SAME in y_train and y_test. (This is good!)\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0, stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2ifIpiFj8Ev"
      },
      "source": [
        "#ColumnTransfromer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "ct = ColumnTransformer(\n",
        "    [('encoder', ohe, ['Embarked', 'Sex']),\n",
        "     ('imputer', imp, ['Age'])],\n",
        "    remainder='passthrough')\n",
        "pipe = Pipeline([('preprocessor', ct), ('classifier', clf)])\n",
        "\n",
        "# ct = make_column_transformer((ohe, make_column_selector(dtype_include=object)))\n",
        "# column transformer with make_column_selector?\n",
        "\n",
        "# set up preprocessing for numeric columns\n",
        "imp_median = SimpleImputer(strategy='median', add_indicator=True)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# set up preprocessing for categorical columns\n",
        "imp_constant = SimpleImputer(strategy='constant')\n",
        "ohe = OneHotEncoder(handle_unknown='ignore')\n",
        "# select columns by data type\n",
        "num_cols = make_column_selector(dtype_include='number')\n",
        "cat_cols = make_column_selector(dtype_exclude='number')\n",
        "\n",
        "# do all preprocessing\n",
        "preprocessor = make_column_transformer(\n",
        "    (make_pipeline(imp_median, scaler), num_cols),\n",
        "    (make_pipeline(imp_constant, ohe), cat_cols))\n",
        "\n",
        "# create a pipeline\n",
        "pipe = make_pipeline(preprocessor, LogisticRegression())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}